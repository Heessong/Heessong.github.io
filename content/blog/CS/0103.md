---
title : '0.1 + 0.2은 0.3일까??'
date : 2021-07-15 21:03:10
category : 'CS'
draft : false
---

코딩을 하다보면 0.1+0.2의 결과값을 출력해보면 값이 딱 떨어지지않는 현상을 볼 수 있는데 이러한 현상이 발생하는 이유를 가볍고 단순하게 얘기하면 인간이 사용하는 10진법의 숫자를 2진법으로 변환하여 처리하는 과정에서 생긴 문제점인데 이런것은 너무 겉핥기식의 이유이다.

```javascript
let a = 0.1;
let b = 0.2;

a + b === 0.3 ) // false
console.log(a + b); // 0.30000000000000004

```

좀 더 자세히 설명해 보자면 많은 프로그래밍 언어에서의 숫자는 IEEE의 컴퓨터에서 부동소수점을 표현하는 가장 널리쓰이는 표준인 `IEEE 754 형식`으로 이루어져 있는데 이 형식으로 표현된 0.1은 `정확히 0.1이 아닌 0.1에 가장 가까운 이진법으로 표현된 근사값`이다.

10진수로 표현되는 소수를 2진수로 표현하려면 몇몇의 경우 무한소수가 발생하게되는데 컴퓨터의 메모리는 무한하지않기 때문에 무한소수를 근사값으로 표현하려다보니 미세하게 값이 달라지는 경우가 생기는 것이다.

<br>

### 해결은 ?

```javascript
(a+b).toFixed(4)	// '0.3000'
parseFloat(a+b).toFixed(4) // 0.3
```

toFixed()메서드를 이용하여 소수점 이후 몇자리까지 표현해줄지 입력하면 된다. 다만 toFixed()는 값을 문자열로 리턴하기때문에 `정수화, 실수화 과정`을 해줘야한다.



```javascript
Math.round((a + b) * 10 / 10); //0.3
```

Math객체 메소드를 이용하는 방법도 있다.



